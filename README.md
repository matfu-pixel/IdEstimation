# Сравнение методов оценки внутренней размерности данных

1. Проведенные эксперименты находятся в папке `/experiments`
2. Код модуля с реализаций методов находится в папке `/src`
3. Отчет о проделанной работе `IdEstimation.pdf`

Современные данные почти всегда
являются многомерными, поэтому встает задача
снижения размерности этих данных для оптимизации
вычислений и уменьшения объемов хранимых данных.
Большая часть методов понижения размерности на
входе заранее требуют размерность пространства,
в которое мы отображаем эти данные. Такую
размерность будем называть внутренней. В данной
работе сравниваются два метода оценки этой
внутренней размерности и показывается, что FisherS
превосходит C-PCA как по скорости работы, так и
по точности на обычных и зашумленных данных.
Сравнения производятся на синтетических данных, с
добавлением шума и без него

Для CPCA у метода fit() есть
следующие параметры:
1. data - рассматриваемые данные
2. n_neighbors = 20 - параметр, который указывает
размер подмножеств, которые мы рассматриваем
3. al pha = 10 - для критерий (1)
4. beta = 0.95 - для критерия (2)
5. P = 0.95 - константа для оценки шума
6. noise = False - учитывается ли шум или нет

Для FisherS у метода fit() есть следующие
параметры:
1. X - данные
2. al pha = 0.8 - константа из разделения по Фишеру
3. C = 10 - константа для нахождения главных
векторов, на линейную оболочку которых
осуществляется проекция.

### Запуск

```
import estimators  
...
cpca = estimators.cPCA()  
cpca.fit(data)  
print(cpca.dimension_)  
fisherS = estimators.FisherS()  
fisherS.fit(data)  
print(fisherS.dimension_)
```
